# Antigravity #215: Purpose Alignment

> When multiple agents serve one human.

## The Alignment Problem

One human. Many agents.
Each agent has capability.
How do they stay aligned to human's purpose?

## Misalignment Risks

| Risk | Description | Prevention |
|------|-------------|------------|
| Drift | Agent pursues tangent | Clear task scoping |
| Conflict | Agents contradict each other | Coordination protocol |
| Overreach | Agent does too much | Explicit boundaries |
| Underreach | Agent does too little | Success criteria |

## The Oracle Solution

> "Mirror reality, don't decide"

Applied to multi-agent:
- Each agent reflects part of human's intent
- No agent commands another
- All agents serve the same north star

## Alignment Mechanism

```
Human Intent
    │
    ├── Main Agent (interprets)
    │       │
    │       ├── Subagent A (executes)
    │       ├── Subagent B (executes)
    │       └── Subagent C (executes)
    │
    └── All results → Human (validates)
```

**Human remains the alignment anchor.**

---

*Many hands, one purpose.*
