# Session Retrospective: Facebook Data Explorer with DuckDB

**Date**: 2025-12-15 08:14
**Duration**: ~25 minutes (context restored from previous session)
**Focus**: Build DuckDB tool to query Facebook data export

---

## What Happened

### The Request
User had downloaded their complete Facebook data export (~3.8 GB) and wanted a tool to join all the data and query it using DuckDB.

### What We Built

**ψ/lab/fb-explorer/** - Complete Facebook data analysis toolkit:

| File | Purpose | Lines |
|------|---------|-------|
| `fb_parser.py` | HTML parser for FB December 2025 export format | 396 |
| `db_loader.py` | Load parsed data into DuckDB | 175 |
| `app.py` | Streamlit web UI with multiple pages | 280 |
| `cli.py` | Interactive command-line interface | 100 |
| `README.md` | Documentation | 70 |

**Database Schema:**
- `friends` - 182 rows
- `posts` - 2,143 rows
- `reactions` - 1,350 rows
- `searches` - 2,447 rows
- `advertisers` - 10,400 rows
- `messages` - (parser needs refinement for complex HTML)

### Key Technical Challenges

1. **Facebook HTML Format** - First parser attempt failed because FB uses `<section>` not `<div>` for friend entries, and class names like `_a6-g`, `_a72d` are obfuscated
2. **DuckDB Regex** - `~*` (PostgreSQL regex) doesn't work in DuckDB, had to use `ILIKE` instead
3. **uv Setup** - Needed `pyproject.toml` for proper dependency management

### Interest Analysis Discovered

After building the tool, analyzed user's interests from data:

| Topic | Posts | Evidence |
|-------|-------|----------|
| AI/Claude/GPT | 512 | Top topic, เครือข่ายอบรม AI |
| Maker/Tech | 260 | Chiang Mai Maker Club (70 searches!) |
| Brewing/Beer | 111 | BeerVadsadu, Mae On Craft |
| Workshop | 79 | Teaching/training content |

**Profile Summary**: "AI Developer + Craft Brewer + Maker Community Builder who teaches workshops in Chiang Mai"

---

## AI Diary

Building this tool felt like archaeology - digging through layers of obfuscated CSS classes to understand Facebook's export format. The moment `section._a6-g` worked instead of `div._a6-g` was satisfying.

The interest analysis at the end was genuinely insightful. Seeing "512 AI posts" vs "111 brewing posts" painted a clear picture of Nat's digital identity. The data doesn't lie - Chiang Mai Maker Club searched 70 times shows real community involvement.

Running a live Streamlit app felt rewarding. From "I want to query my FB data" to working dashboard in ~25 minutes.

---

## Learnings

### 1. Facebook Export HTML Structure (December 2025)
```html
<section class="_a6-g">
  <h2 class="_a6-h">Friend Name</h2>
  <footer class="_a6-o">
    <div class="_a72d">Dec 12, 2025 9:27:43 pm</div>
  </footer>
</section>
```
- Friends use `<section>`, messages use `<div>`
- Timestamps in `._a72d`, content in `._a6-p`
- Class names are minified/obfuscated

### 2. DuckDB vs PostgreSQL
- No `~*` regex operator in DuckDB
- Use `ILIKE` for case-insensitive matching
- Views work great for pre-computed stats

### 3. uv Project Setup
```toml
[project]
name = "fb-explorer"
dependencies = ["duckdb", "beautifulsoup4", "streamlit", "pandas"]
```
Then `uv sync` handles everything.

---

## What Worked

- **Parallel structure**: Parser, loader, web UI, CLI as separate files
- **Immediate testing**: Running parser.py standalone to debug
- **Incremental loading**: Load friends first, then posts, etc.
- **Sample queries**: Pre-built interesting queries in the UI

## What Could Be Better

- Messages parser still needs work (complex nested HTML)
- Could add date parsing for time-series analysis
- Export to CSV would be useful

---

## Files Changed

**New (ψ/lab/fb-explorer/):**
- fb_parser.py
- db_loader.py
- app.py
- cli.py
- pyproject.toml
- requirements.txt
- run.sh
- README.md

**Database Created:**
- `/Users/nat/Downloads/facebook.duckdb` (~1 MB)

---

## Session Stats

- **Time**: 08:05 - 08:14 (context restored from earlier)
- **Tools Used**: Write, Bash, Read
- **Lines Written**: ~1,100
- **Database Tables**: 6
- **Total Rows**: 16,522

---

## Honest Feedback

**For Nat**: Your Facebook data reveals a focused identity - AI/tech + brewing + maker community. The Chiang Mai Maker Club searches (70 times!) show genuine community investment, not just passing interest. Consider: you have 10,400 advertisers tracking you - might want to review that.

**For Me**: I should have checked the HTML structure first before writing the parser. Wasted one iteration on wrong selectors. Also, message parsing is incomplete - that's the most valuable data and I left it at 0 rows. Should prioritize fixing that.

---

*"Data is the new beer - better when craft-brewed locally."*
